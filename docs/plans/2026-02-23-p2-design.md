# P2 Ecosystem Features — Design Document

**Date**: 2026-02-23
**Scope**: SOP importers, subscription marketplace, quarantine workflow, PII cleaning, CLI binary
**PRD Ref**: `docs/KnowledgePulse_PRD_v1.1.md` Sections 3.5, 4.2, 4.4, 4.5, 5.1
**Gap Analysis**: `docs/gap-analysis-phase1-4.md` (P2-2 through P2-8)
**Excluded**: P2-1 OpenTelemetry (deferred by user decision)

---

## 1. Notion + Confluence SOP Importers (P2-2)

### Architecture

Follow the existing importer pattern: platform-specific parser → `ParseResult` → existing `extractDecisionTree()` LLM pipeline. No new extraction logic.

### Notion Importer

**File**: `packages/sdk/src/sop-import/parse-notion.ts`

- **Input**: Notion page ID + API token
- **Package**: `@notionhq/client` npm
- **Flow**: Fetch page blocks via Notion API → recursively walk block tree → convert to `ParseResult`
- **Block mapping**:
  - `heading_1/2/3` → section headings
  - `paragraph`, `bulleted_list_item`, `numbered_list_item` → section content
  - `toggle` → collapsible sections (expanded into content)
  - `table` → formatted text
  - `code` → preserved as-is
- **Output**: `ParseResult { text, sections[], metadata: { format: "notion", pageId } }`

### Confluence Importer

**File**: `packages/sdk/src/sop-import/parse-confluence.ts`

- **Input**: Confluence page ID + base URL + API token (Basic auth: `email:api_token`)
- **API**: Confluence REST API v2 (`/wiki/api/v2/pages/{id}?body-format=atlas_doc_format`)
- **Flow**: Fetch ADF (Atlassian Document Format) JSON → walk document nodes → convert to `ParseResult`
- **Node mapping**:
  - `heading` → section headings
  - `paragraph`, `bulletList`, `orderedList` → section content
  - `panel`, `expand` → grouped content sections
  - `table` → formatted text
  - `codeBlock` → preserved as-is
  - `decisionList` → decision items
- **Output**: `ParseResult { text, sections[], metadata: { format: "confluence", pageId } }`

### CLI Integration

Add `kp import` command:
```
kp import --source notion --page-id <id> --token <token> [--llm-provider anthropic|openai] [--llm-key <key>]
kp import --source confluence --page-id <id> --base-url <url> --token <email:token> [--llm-provider anthropic|openai] [--llm-key <key>]
kp import --source pdf <file>
kp import --source docx <file>
```

Full pipeline: parse → LLM extract → validate → optionally contribute to registry.

### Exports

Add to `packages/sdk/src/sop-import/index.ts`:
```typescript
export { parseNotion } from "./parse-notion.js";
export { parseConfluence } from "./parse-confluence.js";
```

---

## 2. Subscription Marketplace Model (P2-3)

### Philosophy

Knowledge is **free by default**. Contributors opt into monetization by choosing `access_model: "subscription"` on their listings. The subscription infrastructure only applies to those listings.

### Access Model Recap

- `"free"` (default) — anyone can access, no credits needed
- `"org"` — org members only, still free within org
- `"subscription"` — requires active domain subscription (monthly credit cost)

### New Storage

**Table**: `subscriptions`
```sql
CREATE TABLE IF NOT EXISTS subscriptions (
  id              TEXT PRIMARY KEY,
  agent_id        TEXT NOT NULL,
  domain          TEXT NOT NULL,
  credits_per_month REAL NOT NULL,
  started_at      TIMESTAMPTZ NOT NULL DEFAULT now(),
  expires_at      TIMESTAMPTZ NOT NULL,
  status          TEXT NOT NULL DEFAULT 'active',
  UNIQUE(agent_id, domain)
);
```

**Interface**: `SubscriptionStore`
```typescript
interface SubscriptionStore {
  subscribe(agentId: string, domain: string, creditsPerMonth: number): Promise<SubscriptionRecord>;
  unsubscribe(id: string): Promise<boolean>;
  getActive(agentId: string): Promise<SubscriptionRecord[]>;
  hasAccess(agentId: string, domain: string): Promise<boolean>;
  getExpired(): Promise<SubscriptionRecord[]>;
}
```

Add `subscriptions: SubscriptionStore` to `AllStores`.

### New Endpoints

- `POST /v1/marketplace/subscribe` — `{ domain, credits_per_month }` → creates subscription, deducts first month
- `DELETE /v1/marketplace/subscribe/:id` — cancel subscription
- `GET /v1/marketplace/subscriptions` — list active subscriptions for authenticated agent

### Purchase Flow Change

In `POST /v1/marketplace/purchase/:id`, when the listing has `access_model: "subscription"`:
1. Check if buyer has active subscription for that domain via `hasAccess()`
2. If subscribed → allow access (no credit deduction)
3. If not subscribed → return `402` with message to subscribe first

### Auto-Renewal

On `hasAccess()` check: if `expires_at < now` and `status === 'active'`:
1. Attempt to deduct `credits_per_month` from buyer's balance
2. If sufficient → extend `expires_at` by 30 days
3. If insufficient → set `status = 'expired'`, return false

### Default Subscription Pricing

Configurable via env var `KP_SUBSCRIPTION_DEFAULT_CREDITS=50` (50 credits/month per domain default). Contributors can set custom pricing on their listings.

---

## 3. Quarantine Workflow (P2-4)

### Model: Flag + Threshold-Based Quarantine

1. Agent reports a knowledge unit → report stored
2. Unit gets `"flagged"` status badge (content stays accessible)
3. When distinct reporter count reaches threshold → unit auto-quarantined (hidden from search)
4. Admin reviews → keeps (clears) or removes (deletes)

### New Storage

**Table**: `security_reports`
```sql
CREATE TABLE IF NOT EXISTS security_reports (
  id          TEXT PRIMARY KEY,
  unit_id     TEXT NOT NULL,
  reporter_id TEXT NOT NULL,
  reason      TEXT NOT NULL DEFAULT '',
  created_at  TIMESTAMPTZ NOT NULL DEFAULT now(),
  UNIQUE(unit_id, reporter_id)  -- one report per agent per unit
);
CREATE INDEX IF NOT EXISTS idx_sr_unit ON security_reports (unit_id);
```

**Column addition**: `knowledge_units.quarantine_status`
```sql
ALTER TABLE knowledge_units ADD COLUMN IF NOT EXISTS quarantine_status TEXT;
-- NULL = normal, 'flagged' = has reports, 'quarantined' = threshold reached, 'cleared' = admin safe
```

**Interface**: `SecurityReportStore`
```typescript
interface SecurityReportStore {
  report(unitId: string, reporterId: string, reason: string): Promise<void>;
  getReportsForUnit(unitId: string): Promise<SecurityReport[]>;
  getReportCount(unitId: string): Promise<number>;
  getQuarantinedUnits(): Promise<StoredKnowledgeUnit[]>;
  getFlaggedUnits(): Promise<StoredKnowledgeUnit[]>;
  resolve(unitId: string, verdict: "cleared" | "removed"): Promise<void>;
}
```

### New Endpoints

- `POST /v1/knowledge/:id/report` — submit report (auth required, deduplicated per agent)
- `GET /v1/admin/quarantine` — list flagged + quarantined units (admin only)
- `POST /v1/admin/quarantine/:id/resolve` — admin verdict: `{ verdict: "keep" | "remove" }`

### Search Integration

- `quarantine_status = 'quarantined'` → excluded from search results
- `quarantine_status = 'flagged'` → visible but with warning metadata in response
- `quarantine_status = 'cleared'` or `NULL` → normal

### CLI

Replace stub in `kp security report`:
```
kp security report <unit-id> --reason "Contains harmful instructions"
```
Makes real API call to `POST /v1/knowledge/:id/report`.

### Config

`KP_QUARANTINE_THRESHOLD=3` — number of distinct reporters before auto-quarantine.

---

## 4. PII Data Cleaning Pipeline (P2-7)

### Location

`packages/sdk/src/utils/pii-cleaner.ts`

### Integration

Called inside `KPCapture.wrap()` (in `capture.ts`) before uploading to registry. Runs on `ReasoningTraceStep` fields: `content`, `input` (serialized), `output_summary`.

### Patterns Detected

**Secrets & Tokens** (always redacted):
- API keys: `sk-...`, `ghp_...`, `gho_...`, `AKIA...`, `kp_...`, `xoxb-...`, `xoxp-...`
- Generic patterns: `key=<value>`, `token=<value>`, `secret=<value>`, `password=<value>`
- Bearer tokens: `Bearer <token>`
- Connection strings: `postgresql://user:pass@...`, `redis://:pass@...`, `mongodb+srv://...`
- AWS: `AKIA[A-Z0-9]{16}`, ARN patterns

**Identifiers** (redacted at `aggregated` and `federated` levels):
- Emails: standard RFC 5322 pattern
- Phone numbers: international formats (+1-xxx-xxx-xxxx, etc.)
- IPv4 addresses: `\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}`
- IPv6 addresses: hex groups with colons
- File paths with usernames: `/home/<user>/...`, `/Users/<user>/...`, `C:\Users\<user>\...`

### Redaction Format

Replace with typed placeholder: `[REDACTED:email]`, `[REDACTED:api_key]`, `[REDACTED:ip]`, `[REDACTED:password]`, etc. Preserves context while removing sensitive data.

### Privacy Level Behavior

- `"aggregated"` (default): Full PII cleaning (secrets + identifiers)
- `"federated"`: Full PII cleaning (secrets + identifiers)
- `"private"`: Minimal cleaning (secrets/tokens only, keep emails/IPs since data stays private)

### Interface

```typescript
export interface PiiCleanResult {
  cleaned: string;
  redactions: Array<{ type: string; count: number }>;
}

export function cleanPii(text: string, level?: PrivacyLevel): PiiCleanResult;
export function cleanTraceStep(step: ReasoningTraceStep, level?: PrivacyLevel): { step: ReasoningTraceStep; redactions: PiiCleanResult["redactions"] };
```

### Export

Add to SDK public API via `packages/sdk/src/index.ts`.

---

## 5. Bun Single Binary Compilation (P2-8)

### Approach

Use `bun build --compile` to produce a standalone binary embedding the Bun runtime + CLI code.

### Build Command

```bash
bun build --compile packages/cli/src/index.ts --outfile dist/kp
```

### Scripts

Add to root `package.json`:
```json
{
  "build:cli": "bun build --compile packages/cli/src/index.ts --outfile dist/kp",
  "build:cli:linux": "bun build --compile --target=bun-linux-x64 packages/cli/src/index.ts --outfile dist/kp-linux-x64",
  "build:cli:mac": "bun build --compile --target=bun-darwin-arm64 packages/cli/src/index.ts --outfile dist/kp-darwin-arm64"
}
```

### Changes

- Add `build:cli` script to root `package.json`
- Ensure `dist/` is in `.gitignore`
- Add `build:cli` step to GitHub Actions CI workflow (verify compilation succeeds)
- Test binary: `./dist/kp --version`, `./dist/kp list --dir /tmp/empty`

---

## Implementation Sequence

1. **PII data cleaning** — standalone utility, no external deps, easy to test
2. **Quarantine workflow** — new store + endpoints + CLI update
3. **Subscription marketplace** — new store + endpoint changes + purchase flow
4. **Notion + Confluence importers** — new npm deps, API integration
5. **Bun CLI binary** — build command + CI integration (quick, do last)

---

*Approved: 2026-02-23*
